<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
	<!--主要的-->
	<property>
        <name>dfs.datanode.data.dir</name>
        <value>/data/dfs</value>
		<description>datanode本地文件存放地址</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.replication</name>
        <value>3</value>
		<description>文件副本数</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.namenode.name.dir</name>
        <value>/data/dfsname</value>
		<description>namenode本地文件存放地址</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.support.append</name>
        <value>true</value>
		<description>是否支持追加</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.permissions.enabled</name>
        <value>false</value>
		<description>是否开启目录权限</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.nameservices</name>
        <value>ns1</value>
		<description>提供服务的NS逻辑名称，与core-site.xml里的对应</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.ha.namenodes.ns1</name>
        <value>nn1,nn2</value>
		<description>列出该逻辑名称下的NameNode逻辑名称</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.namenode.rpc-address.ns1.nn1</name>
        <value>nn1.hadoop:9000</value>
		<description>指定NameNode的RPC位置</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.namenode.http-address.ns1.nn1</name>
        <value>nn1.hadoop:50070</value>
		<description>指定NameNode的Web Service位置</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.namenode.rpc-address.ns1.nn2</name>
        <value>nn2.hadoop:9000</value>
		<description>指定NameNode的RPC位置</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.namenode.http-address.ns1.nn2</name>
        <value>nn2.hadoop:50070</value>
		<description>指定NameNode的Web Service位置</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://nn1.hadoop:8485;nn2.hadoop:8485/ns1</value>
		<description>指定用于HA存放edits的共享存储，通常是namenode的所在机器</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.journalnode.edits.dir</name>
        <value>/data/journaldata/</value>
		<description>journaldata服务存放文件的地址</description>
	</property>
	<property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
		<description>指定HA做隔离的方法，缺省是ssh，可设为shell，稍后详述</description>
	</property>
	<property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/hadoop/.ssh/id_rsa</value>
		<description></description>
	</property>
	<property>
        <name>dfs.client.failover.proxy.provider.ns1</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
		<description>指定客户端用户HA切换的代理类，不同的NS可以用不同的代理类以上示例为Hadoop2.0自带的缺省代理类</description>
	</property>
	<property>
        <name>dfs.client.failover.proxy.provider.auto-ha</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
		<description></description>
	</property>
	<property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
		<description></description>
	</property>
	<!--主要的-->
	<property>
        <name>fs.trash.interval</name>
        <value>2880</value>
		<description>回收周期</description>
	</property>
	<property>
        <name>dfs.datanode.balance.bandwidthPerSec</name>
        <value>104857600</value>
		<description></description>
	</property>
	<property>
        <name>dfs.namenode.handler.count</name>
        <value>77</value>
		<description></description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.blocksize</name>
        <value>268435456</value>
		<description>文件快的大小</description>
	</property>
	<!--DataNode-->
	<property>
        <name>dfs.datanode.max.transfer.threads</name>
        <value>8192</value>
		<description>相当于linux下的打开文件最大数量，文档中无此参数，当出现DataXceiver报错的时候，需要调大。默认256</description>
	</property>
	<!--主要的-->
	<property>
        <name>dfs.datanode.du.reserved</name>
        <value>2147483648</value>
		<description>每个存储卷保留用作其他用途的磁盘大小</description>
	</property>
	<property>
        <name>dfs.datanode.fsdataset.volume.choosing.policy</name>
        <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy</value>
		<description>存储卷选择策略</description>
	</property>
	<property>
        <name>dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold</name>
        <value>2147483648</value>
		<description>允许的卷剩余空间差值，2G</description>
	</property>
	<property>
        <name>dfs.client.read.shortcircuit</name>
        <value>true</value>
		<description></description>
	</property>
	<property>
        <name>dfs.domain.socket.path</name>
        <value>/data/dn_socket_PORT</value>
		<description></description>
	</property>
</configuration>
